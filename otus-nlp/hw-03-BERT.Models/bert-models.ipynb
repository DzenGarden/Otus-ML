{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28181fe4-2250-4ba4-8a4e-23de3fcf9e15",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Почувствуй мощь трансформеров в бою\n",
    "\n",
    "**Цель**:\n",
    "\n",
    "Научиться работать с трансформерными моделями и применять их для различных NLP задач.\n",
    "\n",
    "**Описание/Пошаговая инструкция выполнения домашнего задания:**\n",
    "\n",
    "В качестве данных выберете возьмите датасет RuCoLA для русского языка https://github.com/RussianNLP/RuCoLA (в качестве train возьмите in_domain_train.csv, а в качестве теста in_domain_dev.csv).\n",
    "\n",
    "Разбейте in_domain_train на train и val.\n",
    "\n",
    "1. Зафайнтьюньте и протестируйте RuBert или RuRoBerta на данной задаче (можно взять любую предобученную модель руберт с сайта huggingface. Например, ruBert-base/large https://huggingface.co/sberbank-ai/ruBert-base / https://huggingface.co/sberbank-ai/ruBert-large или rubert-base-cased https://huggingface.co/DeepPavlov/rubert-base-cased, ruRoberta-large https://huggingface.co/sberbank-ai/ruRoberta-large, xlm-roberta-base https://huggingface.co/xlm-roberta-base).\n",
    "\n",
    "2. Возьмите RuGPT3 base или large и решите данное задание с помощью методов few-/zero-shot.\n",
    "\n",
    "а) переберите несколько вариантов затравок;\n",
    "\n",
    "б) протестируйте различное число few-shot примеров (0, 1, 2, 4).\n",
    "\n",
    "3. Обучите и протестируйте модель RuT5 на данной задаче (пример finetun’а можете найти здесь https://github.com/RussianNLP/RuCoLA/blob/main/baselines/finetune_t5.py).\n",
    "\n",
    "Сравните полученные результаты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0054ba7f-dbe0-400e-a68c-775f73d77618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from transformers import pipeline, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ead79-1eba-48e0-85ee-5ab17a64d8d5",
   "metadata": {},
   "source": [
    "## 1. RuBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab6ac3-2053-413d-ac7c-e2bd9f54cf99",
   "metadata": {},
   "source": [
    "### 1.1 Загружаем датасет RuCoLa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1820f993-21c6-4065-9783-8053dc989257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/in_domain_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/in_domain_dev.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfa2de7-8376-4093-ae36-bc554c871684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вдруг решетка беззвучно поехала в сторону, и н...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Этим летом не никуда ездили.</td>\n",
       "      <td>0</td>\n",
       "      <td>Syntax</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Только Иван выразил какую бы то ни было готовн...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Теперь ты видишь собственными глазами, как тут...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На поверку вся теория оказалась полной чепухой.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>Установки не было введено в действие.</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>Конечно, против такой системы ценностей решите...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>Симптомов болезни не исчезло.</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>Послезавтра температура у больного снижается д...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>Говоря, например, о картине Александра Иванова...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7869 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  acceptable  \\\n",
       "id                                                                    \n",
       "0     Вдруг решетка беззвучно поехала в сторону, и н...           1   \n",
       "1                          Этим летом не никуда ездили.           0   \n",
       "2     Только Иван выразил какую бы то ни было готовн...           1   \n",
       "3     Теперь ты видишь собственными глазами, как тут...           1   \n",
       "4       На поверку вся теория оказалась полной чепухой.           1   \n",
       "...                                                 ...         ...   \n",
       "7864              Установки не было введено в действие.           0   \n",
       "7865  Конечно, против такой системы ценностей решите...           0   \n",
       "7866                      Симптомов болезни не исчезло.           0   \n",
       "7867  Послезавтра температура у больного снижается д...           0   \n",
       "7868  Говоря, например, о картине Александра Иванова...           0   \n",
       "\n",
       "     error_type detailed_source  \n",
       "id                               \n",
       "0             0   Paducheva2004  \n",
       "1        Syntax         Rusgram  \n",
       "2             0   Paducheva2013  \n",
       "3             0   Paducheva2010  \n",
       "4             0   Paducheva2010  \n",
       "...         ...             ...  \n",
       "7864  Semantics   Paducheva2004  \n",
       "7865  Semantics   Paducheva2013  \n",
       "7866  Semantics   Paducheva2013  \n",
       "7867  Semantics         Rusgram  \n",
       "7868  Semantics   Paducheva2013  \n",
       "\n",
       "[7869 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1df174-3e57-43cc-90ca-96fa5f14eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7869 entries, 0 to 7868\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sentence         7869 non-null   object\n",
      " 1   acceptable       7869 non-null   int64 \n",
      " 2   error_type       7869 non-null   object\n",
      " 3   detailed_source  7869 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 307.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd831432-424a-419f-b3f0-ea68d06a8662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 983 entries, 0 to 982\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sentence         983 non-null    object\n",
      " 1   acceptable       983 non-null    int64 \n",
      " 2   error_type       983 non-null    object\n",
      " 3   detailed_source  983 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 38.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92e53f5-55c0-4998-bba7-594ba98f0c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"acceptable\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97a0219-c2f2-40d6-8b26-46b4631d653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"acceptable\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c0bc1c-134a-4fe2-903c-cde7213744c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceptable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5864</td>\n",
       "      <td>5864</td>\n",
       "      <td>5864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentence  error_type  detailed_source\n",
       "acceptable                                       \n",
       "0               2005        2005             2005\n",
       "1               5864        5864             5864"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"acceptable\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d778386-6100-4e40-884b-384ca945479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptable\n",
       "1    5864\n",
       "0    2005\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"acceptable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e590ca-490b-4bb8-a207-c70f7e0bf57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"error_type\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf493754-72a3-436f-8f56-0bdf719c4640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'Syntax', 'Semantics', 'Morphology'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"error_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b76142e6-1c6a-4e60-bb3d-fc9d63428b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3927"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = random.randint(0, df_train.shape[0]-1)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8dc6510-999b-40d6-a519-653b7a335e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Когда я вернулся, он спал.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sentence[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360195e-6e4d-4432-86d8-8ad326b16898",
   "metadata": {},
   "source": [
    "## 1.1. Подготовим датасет для работы с моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c28d5cf-9c16-4b43-b521-9a63ac424606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 7869\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_dict({'text':df_train.sentence, 'label':df_train.acceptable}, split='train')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f8620d-16f8-4333-8064-8fc15964041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8ae8f6-7f51-4cf3-b65f-847f8ac52159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 983\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = Dataset.from_dict({'text':df_test.sentence, 'label':df_test.acceptable}, split='test')\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34ad92da-f67b-40a7-aac7-4d047ab5c4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'На Марсе есть какие-либо (какие бы то ни было) разумные обитатели.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['text'][982]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966c45e-be34-4a70-9df0-a8462ad7ccd8",
   "metadata": {},
   "source": [
    "## 1.2 Загрузим модель RuBERT с HaggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daf2ed55-743f-467c-bb57-b7b4d8a91f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'ai-forever/ruBert-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44c87a94-4b6a-407a-acf8-47829893e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57af2039-44c1-49ff-b797-2ae5b0fa26b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb41070-cc0b-4cfd-a30c-3ae728a4403d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d394537696045e6bff42d27bf5b5fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_tokenized = train_ds.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac2e4d1f-205b-4557-9adb-77a14b819ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86971a3f38854ad9a98a98ebb48622d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/983 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds_tokenized = test_ds.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e930f2de-b37a-4674-a7b3-4c31add60a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'input_ids': [101, 104691, 379, 5171, 672, 14207, 126, 102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41f08029-6157-4594-a632-a486673633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f76b17-2924-42b4-bf14-d099c6eddcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds_tokenized, shuffle=True, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "559b5b23-19b8-420c-85b1-35b83fa0c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_ds_tokenized, shuffle=False, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59caa58e-3294-40ee-ada0-f1004cce7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(base_model, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3da68c7-6d6c-4672-a164-c4766f14f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertForSequenceClassification"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0ef3685-0e60-48b8-bba1-7a6906802e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ca4367-b1e0-4cf1-a95b-f79c6fe9ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a893d69-8874-495e-9619-4e476eb2276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)  # with tiny batches, LR should be very small as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d96c3a7a-fc11-40f4-a384-38e33f3f5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b4df7c8-48b0-4977-8402-de28125ef8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e14fc9d7b3412db0e164c9d41a4d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54c036cb4a84e1ea04de38b8e11531e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537ac26776334b02bdf63f0223c6d833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.5451523773372173 Eval Loss: 0.5358655233451022 Accuracy 0.7507629704984741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da3705271c045f3a492c7a2ad18b045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490d1f497792474084ad5eb882c8dcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.50386698782444 Eval Loss: 0.5134998018421778 Accuracy 0.762970498474059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a380c38cedfb4bb4885e82ccad53b2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0158e3eacc42aebe1635cebc31a9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.5086082202941179 Eval Loss: 0.4913178726243294 Accuracy 0.7812817904374364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07be2075256453cb4729b49d4098b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd26b9f7e5224cd9ab1899ae737c7316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 0.41421750232577326 Eval Loss: 0.5015357464127909 Accuracy 0.780264496439471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b047ad81b14f66b19b6b3b986e0e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667eb7e4a26f4d02844f45e138c0cf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.34821811709553 Eval Loss: 0.5295565909501619 Accuracy 0.7782299084435402\n"
     ]
    }
   ],
   "source": [
    "# set initial best loss to infinite\n",
    "best_eval_loss = float('inf')\n",
    "\n",
    "# empty list to store loss for each epoch\n",
    "losses = []\n",
    "\n",
    "for epoch in trange(5):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    model.train()\n",
    "    for i, batch in enumerate(pbar):\n",
    "        out = model(**batch.to(model.device))\n",
    "        out.loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(out.loss.item())\n",
    "        pbar.set_description(f'loss: {np.mean(losses[-100:]):2.2f}')\n",
    "\n",
    "    model.eval()\n",
    "    eval_losses = []\n",
    "    eval_preds = []\n",
    "    eval_targets = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "                out = model(**batch.to(model.device))\n",
    "        eval_losses.append(out.loss.item())\n",
    "        eval_preds.extend(out.logits.argmax(1).tolist())\n",
    "        eval_targets.extend(batch['labels'].tolist())\n",
    "    print('Epoch:', epoch+1, 'Train Loss:', np.mean(losses[-100:]), 'Eval Loss:', np.mean(eval_losses), 'Accuracy', np.mean(np.array(eval_targets) == eval_preds))\n",
    "    #save the best model\n",
    "    if np.mean(eval_losses) < best_eval_loss:\n",
    "        best_eval_loss = np.mean(eval_losses)\n",
    "        torch.save(model.state_dict(), 'bert_saved_weights.pt')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8063db-fa45-456c-a3b0-304f0a72d1ed",
   "metadata": {},
   "source": [
    "Видим, что в определенный момент validation loss начинает увеличиваться и это означает, что модель переобучается на нашем небольшом наборе данных. Загрузим сохраненную наилучшую модель и посчитаем метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5a63889-948c-4439-8ff8-63c61b31e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(true_y, prediction_y, ndig=3):\n",
    "    \"\"\"\n",
    "    Evaluates and returns the following metrics: Accuracy, Precision, Recall, F1-score, AUC\n",
    "    \"\"\"\n",
    "    accuracy = round(accuracy_score(true_y, prediction_y), ndig)\n",
    "    precision = round(precision_score(true_y, prediction_y), ndig)\n",
    "    recall = round(recall_score(true_y, prediction_y), ndig)\n",
    "    f1 = round(f1_score(true_y, prediction_y), ndig)\n",
    "    auc = round(roc_auc_score(true_y, prediction_y), ndig)\n",
    "    print(f\" Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"   Recall: {recall}\")\n",
    "    print(f\" F1-score: {f1}\")\n",
    "    print(f\"      AUC: {auc}\")\n",
    "    return [accuracy, precision, recall, f1, auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc3419a8-25c8-44c5-b045-25ad5fb0a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f2a8c82-2462-4c68-9331-27c46b09f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40457/2601914036.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'bert_saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13843966-01c9-49f8-abe2-dab1eeead985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b721d519e46e421696d2d4e2b0ce2eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent train loss 0.34821811709553 eval loss 0.4913178726243294 accuracy 0.7812817904374364\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_losses = []\n",
    "eval_preds = []\n",
    "eval_targets = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "            out = model(**batch.to(model.device))\n",
    "    eval_losses.append(out.loss.item())\n",
    "    eval_preds.extend(out.logits.argmax(1).tolist())\n",
    "    eval_targets.extend(batch['labels'].tolist())\n",
    "print('recent train loss', np.mean(losses[-100:]), 'eval loss', np.mean(eval_losses), 'accuracy', np.mean(np.array(eval_targets) == eval_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "627236f9-7537-4bff-a5ea-272fcefbd8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.22      0.33       250\n",
      "           1       0.78      0.97      0.87       733\n",
      "\n",
      "    accuracy                           0.78       983\n",
      "   macro avg       0.76      0.60      0.60       983\n",
      "weighted avg       0.77      0.78      0.73       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_targets, eval_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "219f8f98-d955-40f8-b939-f1e7e1983cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.781\n",
      "Precision: 0.785\n",
      "   Recall: 0.974\n",
      " F1-score: 0.869\n",
      "      AUC: 0.595\n"
     ]
    }
   ],
   "source": [
    "results['ruBERT'] = quality(eval_targets, eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d37bfccc-7767-4dd0-aa98-db1a4c9b36bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT     0.781      0.785   0.974     0.869  0.595"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391e761-e15e-4fe7-966c-14e381627ce8",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc67dc-608f-4fd5-b601-2e95c4423dfe",
   "metadata": {},
   "source": [
    "Для zero-shot классификации воспользуемся стандарным pipeline от Haggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed0fb1-10d1-4d22-b26e-8028e5d864d2",
   "metadata": {},
   "source": [
    "Links (delete later)\n",
    "- [GFG: Zero shot text classification](https://www.geeksforgeeks.org/zero-shot-text-classification-using-huggingface-model/)\n",
    "- [Medium: Map class labels from srings to numbers](https://medium.com/@duzhewang/change-the-class-labels-from-a-string-representation-into-an-integer-format-in-python-using-map-62414d4a1a7e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bf025ee-dcb9-492e-8632-ba80ed64e0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ai-forever/rugpt3large_based_on_gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"ai-forever/rugpt3large_based_on_gpt2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d68ae701-4493-49b0-9135-bca1781eb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Установки не было введено в действие.\"\n",
    "candidate_labels = [\"корректное предложение\", \"некорректное предложение\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be1c6c90-99a0-4790-9446-81dbad908f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Установки не было введено в действие.', 'labels': ['корректное предложение', 'некорректное предложение'], 'scores': [0.504284143447876, 0.495715856552124]}\n"
     ]
    }
   ],
   "source": [
    "result = classifier(text, candidate_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6def57fc-0ac9-45fc-8d99-84be9d72ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Иван вчера не позвонил.\"\n",
    "candidate_labels = [\"некорректное предложение\", \"корректное предложение\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1caa88f1-dea0-4e02-863f-d6c96b531266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Иван вчера не позвонил.', 'labels': ['корректное предложение', 'некорректное предложение'], 'scores': [0.5066623687744141, 0.49333763122558594]}\n"
     ]
    }
   ],
   "source": [
    "result = classifier(text, candidate_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59f419bc-5875-4e68-91db-29f3e6921305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b95d7e0-37e2-4af1-a52d-6eb4f6012e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2873e1a1-643c-40e6-b507-9fb0aab6eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting results in batch режиме\n",
    "zero_shot_out = classifier(test_ds['text'], candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f03e338f-6852-47d1-a591-d04b3b0d3663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zero_shot_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57cf4422-a424-4648-b0ad-3de5962e6813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['корректное предложение', 'некорректное предложение']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_out[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d353b2bd-4a11-48b6-9a2c-6eaea6eb00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting labels usin list comprehension\n",
    "first_labels = [item['labels'][0] for item in zero_shot_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8b03058-5f7b-4145-9eae-1db38acd2787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70b59d0c-aa02-4252-9578-1163a3077dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_preds = list(map(lambda x: 1 if x == 'корректное предложение' else 0, first_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19d71f75-32f7-4128-8ae9-b49b98a4c081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e55b0d28-ec9e-40e6-ac4c-c6142d5f8b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.06      0.11       250\n",
      "           1       0.75      0.95      0.84       733\n",
      "\n",
      "    accuracy                           0.73       983\n",
      "   macro avg       0.53      0.51      0.47       983\n",
      "weighted avg       0.64      0.73      0.65       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_targets, zs_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "907a3a53-2fc2-47fd-b8a4-0a4eff949d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.725\n",
      "Precision: 0.749\n",
      "   Recall: 0.951\n",
      " F1-score: 0.838\n",
      "      AUC: 0.507\n"
     ]
    }
   ],
   "source": [
    "results['Zero-shot'] = quality(eval_targets, zs_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62eef544-4b1a-4bb2-a51c-2df9f8c201d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-shot</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT        0.781      0.785   0.974     0.869  0.595\n",
       "Zero-shot     0.725      0.749   0.951     0.838  0.507"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eaa87e-61f3-46b9-a071-e1e2d8a648ee",
   "metadata": {},
   "source": [
    "В zero-shot варианте результаты несколько хуже, попробуем few-shots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3545e5-7c3a-4db8-a123-7200cfa43685",
   "metadata": {},
   "source": [
    "### Few-shots classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edfae90-41af-4d00-91e9-6f4d91b92a1c",
   "metadata": {},
   "source": [
    "Используем другой подход - будем вызывать инференс модели с few-shot промптом и считать loss для оценки грамматической корректности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3dec1bbe-a027-493c-b5d5-bcf8fa3c2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ee0af66-5b3d-430f-8fb7-3efac71e5e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=4608, nx=1536)\n",
       "          (c_proj): Conv1D(nf=1536, nx=1536)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=6144, nx=1536)\n",
       "          (c_proj): Conv1D(nf=1536, nx=6144)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a361e71-a001-42ae-a4f8-42d134f3c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Иван вчера не позвонил.'\n",
    "few_shots = ['Предложение далее корректное? ' + 'Солнце садилось за горизонт.' + \" Ответ: да.\",\n",
    "             'Предложение далее корректное? ' + 'Не стоит сидеть сложить руки.' + \" Ответ: нет.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b29621a7-409e-4e6c-8b14-2113fa844fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to calculate loss and get predictions\n",
    "def calc_loss(phrase: str,\n",
    "                        tokenizer,\n",
    "                        model):\n",
    "\n",
    "    phrase = tokenizer.encode(phrase)\n",
    "    # Adding <EOS> token in case the given phrase is only 1 token length, to avoid an error\n",
    "    if len(phrase) == 1:\n",
    "         phrase.append(tokenizer.eos_token_id)\n",
    "    phrase = torch.tensor(phrase, dtype=torch.long, device=device)\n",
    "    phrase = phrase.unsqueeze(0)  # .repeat(num_samples, 1)\n",
    "    with torch.no_grad():\n",
    "        loss = model(phrase, labels=phrase)\n",
    "    return loss[0].item()\n",
    "\n",
    "def get_loss_num(text):\n",
    "    loss = calc_loss(phrase=text, model=model, tokenizer=tokenizer)\n",
    "    return loss\n",
    "\n",
    "def get_correct_prompt(phrase, few_shots=few_shots):\n",
    "    return '\\n'.join(few_shots) +'\\nПредложение далее корректное? ' + phrase + \" Ответ: да.\"\n",
    "\n",
    "def get_incorrect_prompt(phrase, few_shots=few_shots):\n",
    "    return '\\n'.join(few_shots) + '\\nПредложение далее корректное? ' + phrase + \" Ответ: нет.\"\n",
    "\n",
    "def get_few_shot_pred(text):\n",
    "    res = {}\n",
    "    #print(get_correct_prompt(text)) ## Debugging\n",
    "    correct_loss = calc_loss(phrase=get_correct_prompt(text), model=model, tokenizer=tokenizer)\n",
    "    #print(f\"Correct Loss: {correct_loss}\") ## Debugiing\n",
    "    \n",
    "    #print(get_incorrect_prompt(text)) ## Debugging\n",
    "    incorrect_loss = calc_loss(phrase=get_incorrect_prompt(text), model=model, tokenizer=tokenizer)\n",
    "    #print(f\"Incorrect Loss: {incorrect_loss}\") ## Debugging\n",
    "\n",
    "    pred_num = 1 if correct_loss < incorrect_loss else 0\n",
    "    \n",
    "    res[\"Correct_Loss\"] = correct_loss\n",
    "    res[\"Inorrect_Loss\"] = incorrect_loss\n",
    "    res[\"pred\"] = pred_num\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f675adea-f395-476c-9a2b-0c778a1f1675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение далее корректное? Солнце садилось за горизонт. Ответ: да.\n",
      "Предложение далее корректное? Не стоит сидеть сложить руки. Ответ: нет.\n",
      "Предложение далее корректное? Иван вчера не позвонил. Ответ: да.\n"
     ]
    }
   ],
   "source": [
    "correct_prompt = get_correct_prompt(text, few_shots)\n",
    "print(correct_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77f1231a-2da2-4f45-84e5-27fda695f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение далее корректное? Солнце садилось за горизонт. Ответ: да.\n",
      "Предложение далее корректное? Не стоит сидеть сложить руки. Ответ: нет.\n",
      "Предложение далее корректное? Иван вчера не позвонил. Ответ: нет.\n"
     ]
    }
   ],
   "source": [
    "incorrect_prompt = get_incorrect_prompt(text, few_shots)\n",
    "print(incorrect_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a65cbe04-692c-458a-91b9-b1d6978fea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Correct_Loss': 2.8430206775665283,\n",
       " 'Inorrect_Loss': 2.852612257003784,\n",
       " 'pred': 1}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = get_few_shot_pred(text)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00e78fd7-ea50-4145-835e-6feb21b1c0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16eef412-78ad-4a45-839a-67e8102918f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe513e99a8f64ceeaea1a79c2edfb1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fewshot_preds = []\n",
    "\n",
    "for text in tqdm(test_ds['text']):\n",
    "    out = get_few_shot_pred(text)\n",
    "    fewshot_preds.append(out['pred'])\n",
    "    #print(out,'\\n') ## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06b47317-7809-44fd-9e72-23c730198d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fewshot_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93d6a237-942a-4d0b-ae1a-1d15e73930ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.12      0.15       250\n",
      "           1       0.74      0.84      0.79       733\n",
      "\n",
      "    accuracy                           0.66       983\n",
      "   macro avg       0.47      0.48      0.47       983\n",
      "weighted avg       0.60      0.66      0.63       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_targets, fewshot_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e85d58c0-6b8e-41f2-b925-720218099e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.66\n",
      "Precision: 0.738\n",
      "   Recall: 0.844\n",
      " F1-score: 0.788\n",
      "      AUC: 0.482\n"
     ]
    }
   ],
   "source": [
    "results['Few-shots'] = quality(eval_targets, fewshot_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d392ade-7468-4cd7-9b88-559513ebe86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-shot</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few-shots</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT        0.781      0.785   0.974     0.869  0.595\n",
       "Zero-shot     0.725      0.749   0.951     0.838  0.507\n",
       "Few-shots     0.660      0.738   0.844     0.788  0.482"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfd98e-f1de-47a0-9a75-5f33b8d20c43",
   "metadata": {},
   "source": [
    "Загадочно, но с few-shots подходом результаты хуже, по сравнению с zero-shot - возможно, надо дополнительно поиграться с примерами в промпте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c56b03-d0a0-4ea5-b8f5-e8724185a00f",
   "metadata": {},
   "source": [
    "## RuT5 finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6370e3-97c1-4124-84c7-aea4bec45e18",
   "metadata": {},
   "source": [
    "Обучите и протестируйте модель [RuT5](https://huggingface.co/ai-forever/ruT5-base) на данной задаче - пример finetun’а можете найти [здесь](https://github.com/RussianNLP/RuCoLA/blob/main/baselines/finetune_t5.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31c0a7-4665-4312-93a5-da62e3687bff",
   "metadata": {},
   "source": [
    "RuT5 finetuning\n",
    "```python\n",
    "python baselines/finetune_t5.py -m [MODEL_NAME]\n",
    "```\n",
    "Afterwards, you can get test set predictions in the format required by the leaderboard for all trained models. To do this, run \n",
    "```python\n",
    "python baselines/get_csv_predictions.py -m MODEL1 MODEL2 ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "80fbb549-abca-4d5f-90dc-f983cceb2295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40457/1228721719.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  ACCURACY = load_metric(\"accuracy\", keep_in_memory=True)\n",
      "/home/vlad/anaconda3/envs/otus/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bf09145b784229ac27bf0379d130a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/anaconda3/envs/otus/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for matthews_correlation contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/matthews_correlation/matthews_correlation.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dbe68424fa4d4eafde97629dbcfb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACCURACY = load_metric(\"accuracy\", keep_in_memory=True)\n",
    "MCC = load_metric(\"matthews_correlation\", keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcd369ce-0609-4ae5-a1b7-443b0057a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t5_name = \"ai-forever/ruT5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "559cfd1c-99e2-4adb-8e58-4f0f2faaa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 10\n",
    "N_EPOCHS = 20\n",
    "LR_VALUE = (1e-3,)\n",
    "DECAY_VALUE = (1e-4,)\n",
    "BATCH_SIZES = (128,)\n",
    "\n",
    "POS_LABEL = \"yes\"\n",
    "NEG_LABEL = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7317a1b6-3e6e-4473-96cf-605ef2cf4f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c438fcfe87154c25b18f81238ad9c430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9519934e9394337a37ac5df2c259824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725cdeac6288438eaaa67e43d9f17e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_t5_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c00c8b5a-82d4-4c2d-b0bb-cd85c976e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "TRAIN_FILE = DATA_DIR + \"/\" + \"in_domain_train.csv\"\n",
    "IN_DOMAIN_DEV_FILE = DATA_DIR + \"/\" + \"in_domain_dev.csv\"\n",
    "OUT_OF_DOMAIN_DEV_FILE = DATA_DIR + \"/\" + \"out_of_domain_dev.csv\"\n",
    "TEST_FILE = DATA_DIR + \"/\" + \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f326663e-17cd-4972-ab75-9c613bc1614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            TRAIN_FILE -> ./data/in_domain_train.csv\n",
      "    IN_DOMAIN_DEV_FILE -> ./data/in_domain_dev.csv\n",
      "OUT_OF_DOMAIN_DEV_FILE -> ./data/out_of_domain_dev.csv\n",
      "             TEST_FILE -> ./data/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"            TRAIN_FILE -> {TRAIN_FILE}\")\n",
    "print(f\"    IN_DOMAIN_DEV_FILE -> {IN_DOMAIN_DEV_FILE}\")\n",
    "print(f\"OUT_OF_DOMAIN_DEV_FILE -> {OUT_OF_DOMAIN_DEV_FILE}\")\n",
    "print(f\"             TEST_FILE -> {TEST_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4dc47a79-4237-4bf6-8472-1f6a4d48855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_splits(*, as_datasets):\n",
    "    train_df, test_df = map(\n",
    "        pd.read_csv, (TRAIN_FILE, IN_DOMAIN_DEV_FILE)\n",
    "    )\n",
    "\n",
    "    # concatenate datasets to get aggregate metrics\n",
    "    #dev_df = pd.concat((in_domain_dev_df, out_of_domain_dev_df))\n",
    "\n",
    "    if as_datasets:\n",
    "        train, test = map(Dataset.from_pandas, (train_df, test_df))\n",
    "        return DatasetDict(train=train, test=test)\n",
    "    else:\n",
    "        return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3ea5622a-10ba-45cc-86d8-a14169ed2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to prepare datasets here\n",
    "splits = read_splits(as_datasets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "24022587-2e25-4a50-82bc-30ce63296baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sentence', 'acceptable', 'error_type', 'detailed_source'],\n",
       "        num_rows: 7869\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'sentence', 'acceptable', 'error_type', 'detailed_source'],\n",
       "        num_rows: 983\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09633d-5dce-4d7c-9ff5-5a8fdfd3025f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e2ae9-904b-4673-b356-96f7c02c3d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77180bd6-6e7d-4126-954b-708743b3c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_splits = splits.map(\n",
    "        partial(preprocess_examples, tokenizer=tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=[\"sentence\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3b93e848-e02a-4e76-95c1-20d81b705d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 7869\n",
       "})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_ds_tokenized = train_ds.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ddc24004-9ec0-4967-b340-ab89a31def28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 983\n",
       "})"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_ds_tokenized = test_ds.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19550f-be36-4d99-a778-7b61e9e3ce2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f51fda41-e9ac-499c-8a22-a6235b5e1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8883d21-29f0-4d36-8fa5-c912fcf6c4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ce1ac-bbce-4d3f-98a3-28e9dac46714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d21e929b-9bc7-4c9b-9095-9dbfbf78d6d3",
   "metadata": {},
   "source": [
    "## Итоговое сравнение полученных результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a401f0d-a501-4b32-84fb-816cc79f46b6",
   "metadata": {},
   "source": [
    "Отсортируем полученные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05a12c79-146e-4a34-9f65-7da6410e744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-shot</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few-shots</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT        0.781      0.785   0.974     0.869  0.595\n",
       "Zero-shot     0.725      0.749   0.951     0.838  0.507\n",
       "Few-shots     0.660      0.738   0.844     0.788  0.482"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T.sort_values(by=['AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cb5de-ce58-4b2c-bcf4-105ed31a2edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
