{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28181fe4-2250-4ba4-8a4e-23de3fcf9e15",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Почувствуй мощь трансформеров в бою\n",
    "\n",
    "**Цель**:\n",
    "\n",
    "Научиться работать с трансформерными моделями и применять их для различных NLP задач.\n",
    "\n",
    "**Описание/Пошаговая инструкция выполнения домашнего задания:**\n",
    "\n",
    "В качестве данных выберете возьмите датасет RuCoLA для русского языка https://github.com/RussianNLP/RuCoLA (в качестве train возьмите in_domain_train.csv, а в качестве теста in_domain_dev.csv).\n",
    "\n",
    "Разбейте in_domain_train на train и val.\n",
    "\n",
    "1. Зафайнтьюньте и протестируйте RuBert или RuRoBerta на данной задаче (можно взять любую предобученную модель руберт с сайта huggingface. Например, ruBert-base/large https://huggingface.co/sberbank-ai/ruBert-base / https://huggingface.co/sberbank-ai/ruBert-large или rubert-base-cased https://huggingface.co/DeepPavlov/rubert-base-cased, ruRoberta-large https://huggingface.co/sberbank-ai/ruRoberta-large, xlm-roberta-base https://huggingface.co/xlm-roberta-base).\n",
    "\n",
    "2. Возьмите RuGPT3 base или large и решите данное задание с помощью методов few-/zero-shot.\n",
    "\n",
    "а) переберите несколько вариантов затравок;\n",
    "\n",
    "б) протестируйте различное число few-shot примеров (0, 1, 2, 4).\n",
    "\n",
    "3. Обучите и протестируйте модель RuT5 на данной задаче (пример finetun’а можете найти здесь https://github.com/RussianNLP/RuCoLA/blob/main/baselines/finetune_t5.py).\n",
    "\n",
    "Сравните полученные результаты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0054ba7f-dbe0-400e-a68c-775f73d77618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from transformers import pipeline, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ead79-1eba-48e0-85ee-5ab17a64d8d5",
   "metadata": {},
   "source": [
    "## 1. RuBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab6ac3-2053-413d-ac7c-e2bd9f54cf99",
   "metadata": {},
   "source": [
    "### 1.1 Загружаем датасет RuCoLa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1820f993-21c6-4065-9783-8053dc989257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/in_domain_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/in_domain_dev.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfa2de7-8376-4093-ae36-bc554c871684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вдруг решетка беззвучно поехала в сторону, и н...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Этим летом не никуда ездили.</td>\n",
       "      <td>0</td>\n",
       "      <td>Syntax</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Только Иван выразил какую бы то ни было готовн...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Теперь ты видишь собственными глазами, как тут...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На поверку вся теория оказалась полной чепухой.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paducheva2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>Установки не было введено в действие.</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>Конечно, против такой системы ценностей решите...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>Симптомов болезни не исчезло.</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>Послезавтра температура у больного снижается д...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Rusgram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>Говоря, например, о картине Александра Иванова...</td>\n",
       "      <td>0</td>\n",
       "      <td>Semantics</td>\n",
       "      <td>Paducheva2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7869 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  acceptable  \\\n",
       "id                                                                    \n",
       "0     Вдруг решетка беззвучно поехала в сторону, и н...           1   \n",
       "1                          Этим летом не никуда ездили.           0   \n",
       "2     Только Иван выразил какую бы то ни было готовн...           1   \n",
       "3     Теперь ты видишь собственными глазами, как тут...           1   \n",
       "4       На поверку вся теория оказалась полной чепухой.           1   \n",
       "...                                                 ...         ...   \n",
       "7864              Установки не было введено в действие.           0   \n",
       "7865  Конечно, против такой системы ценностей решите...           0   \n",
       "7866                      Симптомов болезни не исчезло.           0   \n",
       "7867  Послезавтра температура у больного снижается д...           0   \n",
       "7868  Говоря, например, о картине Александра Иванова...           0   \n",
       "\n",
       "     error_type detailed_source  \n",
       "id                               \n",
       "0             0   Paducheva2004  \n",
       "1        Syntax         Rusgram  \n",
       "2             0   Paducheva2013  \n",
       "3             0   Paducheva2010  \n",
       "4             0   Paducheva2010  \n",
       "...         ...             ...  \n",
       "7864  Semantics   Paducheva2004  \n",
       "7865  Semantics   Paducheva2013  \n",
       "7866  Semantics   Paducheva2013  \n",
       "7867  Semantics         Rusgram  \n",
       "7868  Semantics   Paducheva2013  \n",
       "\n",
       "[7869 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1df174-3e57-43cc-90ca-96fa5f14eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7869 entries, 0 to 7868\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sentence         7869 non-null   object\n",
      " 1   acceptable       7869 non-null   int64 \n",
      " 2   error_type       7869 non-null   object\n",
      " 3   detailed_source  7869 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 307.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd831432-424a-419f-b3f0-ea68d06a8662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 983 entries, 0 to 982\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sentence         983 non-null    object\n",
      " 1   acceptable       983 non-null    int64 \n",
      " 2   error_type       983 non-null    object\n",
      " 3   detailed_source  983 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 38.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92e53f5-55c0-4998-bba7-594ba98f0c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"acceptable\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97a0219-c2f2-40d6-8b26-46b4631d653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"acceptable\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c0bc1c-134a-4fe2-903c-cde7213744c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>detailed_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceptable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5864</td>\n",
       "      <td>5864</td>\n",
       "      <td>5864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentence  error_type  detailed_source\n",
       "acceptable                                       \n",
       "0               2005        2005             2005\n",
       "1               5864        5864             5864"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"acceptable\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d778386-6100-4e40-884b-384ca945479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptable\n",
       "1    5864\n",
       "0    2005\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"acceptable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e590ca-490b-4bb8-a207-c70f7e0bf57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"error_type\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf493754-72a3-436f-8f56-0bdf719c4640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'Syntax', 'Semantics', 'Morphology'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"error_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b76142e6-1c6a-4e60-bb3d-fc9d63428b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4557"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = random.randint(0, df_train.shape[0]-1)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8dc6510-999b-40d6-a519-653b7a335e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я показал этот текст студентам, самим сведущим в эскимосском языке.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sentence[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360195e-6e4d-4432-86d8-8ad326b16898",
   "metadata": {},
   "source": [
    "## 1.1. Подготовим датасет для работы с моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c28d5cf-9c16-4b43-b521-9a63ac424606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 7869\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_dict({'text':df_train.sentence, 'label':df_train.acceptable}, split='train')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f8620d-16f8-4333-8064-8fc15964041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8ae8f6-7f51-4cf3-b65f-847f8ac52159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 983\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = Dataset.from_dict({'text':df_test.sentence, 'label':df_test.acceptable}, split='test')\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34ad92da-f67b-40a7-aac7-4d047ab5c4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'На Марсе есть какие-либо (какие бы то ни было) разумные обитатели.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['text'][982]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966c45e-be34-4a70-9df0-a8462ad7ccd8",
   "metadata": {},
   "source": [
    "## 1.2 Загрузим модель RuBERT с HaggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daf2ed55-743f-467c-bb57-b7b4d8a91f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'ai-forever/ruBert-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44c87a94-4b6a-407a-acf8-47829893e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57af2039-44c1-49ff-b797-2ae5b0fa26b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb41070-cc0b-4cfd-a30c-3ae728a4403d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dda53be7095476bad1c43a1fa440d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_tokenized = train_ds.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac2e4d1f-205b-4557-9adb-77a14b819ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4839162197eb49f2b7ed2df738b18078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/983 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds_tokenized = test_ds.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e930f2de-b37a-4674-a7b3-4c31add60a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'input_ids': [101, 104691, 379, 5171, 672, 14207, 126, 102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41f08029-6157-4594-a632-a486673633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f76b17-2924-42b4-bf14-d099c6eddcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds_tokenized, shuffle=True, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "559b5b23-19b8-420c-85b1-35b83fa0c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_ds_tokenized, shuffle=False, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59caa58e-3294-40ee-ada0-f1004cce7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(base_model, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3da68c7-6d6c-4672-a164-c4766f14f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertForSequenceClassification"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0ef3685-0e60-48b8-bba1-7a6906802e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ca4367-b1e0-4cf1-a95b-f79c6fe9ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a893d69-8874-495e-9619-4e476eb2276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)  # with tiny batches, LR should be very small as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d96c3a7a-fc11-40f4-a384-38e33f3f5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b4df7c8-48b0-4977-8402-de28125ef8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca33743240304a7a9c3a0cb03ed99f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7a41c313a845a99196687fa0796367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15612fc1c1894b738010aa2901825a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.5471963772177696 Eval Loss: 0.5304297576469135 Accuracy 0.7497456765005086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14209e3e01154060910e436719978735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267bd17539374b209b59e89145830033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss: 0.5443665070831776 Eval Loss: 0.5106789646594505 Accuracy 0.7660223804679552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02d0ad1214e41538ff98c9a92747489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059abda78d2f465089b3b037436c40c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss: 0.4275951987504959 Eval Loss: 0.5052102941686545 Accuracy 0.7843336724313327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2fedf02e124b7e8fa3aac57afd5714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04cfe2da5f147d091698a328fd13f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 0.37910825200378895 Eval Loss: 0.5350302667092017 Accuracy 0.7822990844354019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5342cbd5a4cd4146b76bf90afabb6a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2128cf3d3a3544e891672e3507143ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.35469891704618933 Eval Loss: 0.5322916297681206 Accuracy 0.7833163784333672\n"
     ]
    }
   ],
   "source": [
    "# set initial best loss to infinite\n",
    "best_eval_loss = float('inf')\n",
    "\n",
    "# empty list to store loss for each epoch\n",
    "losses = []\n",
    "\n",
    "for epoch in trange(5):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    model.train()\n",
    "    for i, batch in enumerate(pbar):\n",
    "        out = model(**batch.to(model.device))\n",
    "        out.loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(out.loss.item())\n",
    "        pbar.set_description(f'loss: {np.mean(losses[-100:]):2.2f}')\n",
    "\n",
    "    model.eval()\n",
    "    eval_losses = []\n",
    "    eval_preds = []\n",
    "    eval_targets = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "                out = model(**batch.to(model.device))\n",
    "        eval_losses.append(out.loss.item())\n",
    "        eval_preds.extend(out.logits.argmax(1).tolist())\n",
    "        eval_targets.extend(batch['labels'].tolist())\n",
    "    print('Epoch:', epoch+1, 'Train Loss:', np.mean(losses[-100:]), 'Eval Loss:', np.mean(eval_losses), 'Accuracy', np.mean(np.array(eval_targets) == eval_preds))\n",
    "    #save the best model\n",
    "    if np.mean(eval_losses) < best_eval_loss:\n",
    "        best_eval_loss = np.mean(eval_losses)\n",
    "        torch.save(model.state_dict(), 'bert_saved_weights.pt')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8063db-fa45-456c-a3b0-304f0a72d1ed",
   "metadata": {},
   "source": [
    "Видим, что в определенный момент validation loss начинает увеличиваться и это означает, что модель переобучается на нашем небольшом наборе данных. Загрузим сохраненную наилучшую модель и посчитаем метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5a63889-948c-4439-8ff8-63c61b31e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(true_y, prediction_y, ndig=3):\n",
    "    \"\"\"\n",
    "    Evaluates and returns the following metrics: Accuracy, Precision, Recall, F1-score, AUC\n",
    "    \"\"\"\n",
    "    accuracy = round(accuracy_score(true_y, prediction_y), ndig)\n",
    "    precision = round(precision_score(true_y, prediction_y), ndig)\n",
    "    recall = round(recall_score(true_y, prediction_y), ndig)\n",
    "    f1 = round(f1_score(true_y, prediction_y), ndig)\n",
    "    auc = round(roc_auc_score(true_y, prediction_y), ndig)\n",
    "    print(f\" Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"   Recall: {recall}\")\n",
    "    print(f\" F1-score: {f1}\")\n",
    "    print(f\"      AUC: {auc}\")\n",
    "    return [accuracy, precision, recall, f1, auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc3419a8-25c8-44c5-b045-25ad5fb0a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f2a8c82-2462-4c68-9331-27c46b09f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5708/2601914036.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'bert_saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13843966-01c9-49f8-abe2-dab1eeead985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd3ef26bef54fc7b8edec3daf0793c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent train loss 0.35469891704618933 eval loss 0.5052102941686545 accuracy 0.7843336724313327\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_losses = []\n",
    "eval_preds = []\n",
    "eval_targets = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "            out = model(**batch.to(model.device))\n",
    "    eval_losses.append(out.loss.item())\n",
    "    eval_preds.extend(out.logits.argmax(1).tolist())\n",
    "    eval_targets.extend(batch['labels'].tolist())\n",
    "print('recent train loss', np.mean(losses[-100:]), 'eval loss', np.mean(eval_losses), 'accuracy', np.mean(np.array(eval_targets) == eval_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "627236f9-7537-4bff-a5ea-272fcefbd8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.20      0.32       250\n",
      "           1       0.78      0.98      0.87       733\n",
      "\n",
      "    accuracy                           0.78       983\n",
      "   macro avg       0.80      0.59      0.59       983\n",
      "weighted avg       0.79      0.78      0.73       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_targets, eval_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "219f8f98-d955-40f8-b939-f1e7e1983cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.784\n",
      "Precision: 0.782\n",
      "   Recall: 0.985\n",
      " F1-score: 0.872\n",
      "      AUC: 0.59\n"
     ]
    }
   ],
   "source": [
    "results['ruBERT'] = quality(eval_targets, eval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d37bfccc-7767-4dd0-aa98-db1a4c9b36bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision  Recall  F1-score   AUC\n",
       "ruBERT     0.784      0.782   0.985     0.872  0.59"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391e761-e15e-4fe7-966c-14e381627ce8",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc67dc-608f-4fd5-b601-2e95c4423dfe",
   "metadata": {},
   "source": [
    "Для zero-shot классификации воспользуемся стандарным pipeline от Haggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed0fb1-10d1-4d22-b26e-8028e5d864d2",
   "metadata": {},
   "source": [
    "Links (delete later)\n",
    "- [GFG: Zero shot text classification](https://www.geeksforgeeks.org/zero-shot-text-classification-using-huggingface-model/)\n",
    "- [Medium: Map class labels from srings to numbers](https://medium.com/@duzhewang/change-the-class-labels-from-a-string-representation-into-an-integer-format-in-python-using-map-62414d4a1a7e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bf025ee-dcb9-492e-8632-ba80ed64e0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ai-forever/rugpt3large_based_on_gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"ai-forever/rugpt3large_based_on_gpt2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d68ae701-4493-49b0-9135-bca1781eb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Установки не было введено в действие.\"\n",
    "candidate_labels = [\"корректное предложение\", \"некорректное предложение\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be1c6c90-99a0-4790-9446-81dbad908f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Установки не было введено в действие.', 'labels': ['некорректное предложение', 'корректное предложение'], 'scores': [0.5474717020988464, 0.4525282680988312]}\n"
     ]
    }
   ],
   "source": [
    "result = classifier(text, candidate_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6def57fc-0ac9-45fc-8d99-84be9d72ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Иван вчера не позвонил.\"\n",
    "candidate_labels = [\"некорректное предложение\", \"корректное предложение\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1caa88f1-dea0-4e02-863f-d6c96b531266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Этим летом не никуда ездили.', 'labels': ['некорректное предложение', 'корректное предложение'], 'scores': [0.5138027667999268, 0.48619723320007324]}\n"
     ]
    }
   ],
   "source": [
    "result = classifier(text, candidate_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59f419bc-5875-4e68-91db-29f3e6921305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b95d7e0-37e2-4af1-a52d-6eb4f6012e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2873e1a1-643c-40e6-b507-9fb0aab6eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting results in batch режиме\n",
    "zero_shot_out = classifier(test_ds['text'], candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f03e338f-6852-47d1-a591-d04b3b0d3663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zero_shot_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57cf4422-a424-4648-b0ad-3de5962e6813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['некорректное предложение', 'корректное предложение']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_out[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d353b2bd-4a11-48b6-9a2c-6eaea6eb00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting labels usin list comprehension\n",
    "first_labels = [item['labels'][0] for item in zero_shot_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8b03058-5f7b-4145-9eae-1db38acd2787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70b59d0c-aa02-4252-9578-1163a3077dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_preds = list(map(lambda x: 1 if x == 'корректное предложение' else 0, first_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19d71f75-32f7-4128-8ae9-b49b98a4c081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e55b0d28-ec9e-40e6-ac4c-c6142d5f8b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.78      0.37       250\n",
      "           1       0.68      0.16      0.26       733\n",
      "\n",
      "    accuracy                           0.32       983\n",
      "   macro avg       0.46      0.47      0.32       983\n",
      "weighted avg       0.57      0.32      0.29       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_targets, zs_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "907a3a53-2fc2-47fd-b8a4-0a4eff949d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.319\n",
      "Precision: 0.684\n",
      "   Recall: 0.162\n",
      " F1-score: 0.262\n",
      "      AUC: 0.471\n"
     ]
    }
   ],
   "source": [
    "results['Zero-shot'] = quality(eval_targets, zs_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62eef544-4b1a-4bb2-a51c-2df9f8c201d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-shot</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT        0.784      0.782   0.985     0.872  0.590\n",
       "Zero-shot     0.319      0.684   0.162     0.262  0.471"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eaa87e-61f3-46b9-a071-e1e2d8a648ee",
   "metadata": {},
   "source": [
    "В zero-shot варианте полученные результаты хуже случайного угадывания... Попробуем few-shots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3545e5-7c3a-4db8-a123-7200cfa43685",
   "metadata": {},
   "source": [
    "### Few-shots classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ceadd-e40d-40b1-a57d-29ddb6ebc579",
   "metadata": {},
   "source": [
    "б) протестируйте различное число few-shot примеров (0, 1, 2, 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edfae90-41af-4d00-91e9-6f4d91b92a1c",
   "metadata": {},
   "source": [
    "Попробуем другой подход - напрямую будем вызывать инференс модели и считать loss для оценки грамматической корректности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3dec1bbe-a027-493c-b5d5-bcf8fa3c2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2ee0af66-5b3d-430f-8fb7-3efac71e5e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=4608, nx=1536)\n",
       "          (c_proj): Conv1D(nf=1536, nx=1536)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=6144, nx=1536)\n",
       "          (c_proj): Conv1D(nf=1536, nx=6144)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7a361e71-a001-42ae-a4f8-42d134f3c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Иван вчера не позвонил.'\n",
    "few_shots = ['Предложение далее корректное? ' + 'Солнце садилось за горизонт.' + \" Ответ: да.\",\n",
    "             'Предложение далее корректное? ' + 'Не стоит сидеть сложить руки.' + \" Ответ: нет.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b29621a7-409e-4e6c-8b14-2113fa844fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to calculate loss and get predictions\n",
    "def calc_loss(phrase: str,\n",
    "                        tokenizer,\n",
    "                        model):\n",
    "\n",
    "    phrase = tokenizer.encode(phrase)\n",
    "    # Adding <EOS> token in case the given phrase is only 1 token length, to avoid an error\n",
    "    if len(phrase) == 1:\n",
    "         phrase.append(tokenizer.eos_token_id)\n",
    "    phrase = torch.tensor(phrase, dtype=torch.long, device=device)\n",
    "    phrase = phrase.unsqueeze(0)  # .repeat(num_samples, 1)\n",
    "    with torch.no_grad():\n",
    "        loss = model(phrase, labels=phrase)\n",
    "    return loss[0].item()\n",
    "\n",
    "def get_loss_num(text):\n",
    "    loss = calc_loss(phrase=text, model=model, tokenizer=tokenizer)\n",
    "    return loss\n",
    "\n",
    "def get_correct_prompt(phrase, few_shots=few_shots):\n",
    "    return '\\n'.join(few_shots) +'\\nПредложение далее корректное? ' + phrase + \" Ответ: да.\"\n",
    "\n",
    "def get_incorrect_prompt(phrase, few_shots=few_shots):\n",
    "    return '\\n'.join(few_shots) + '\\nПредложение далее корректное? ' + phrase + \" Ответ: нет.\"\n",
    "\n",
    "def get_few_shot_pred(text):\n",
    "    res = {}\n",
    "    #print(get_correct_prompt(text)) ## Debugging\n",
    "    correct_loss = calc_loss(phrase=get_correct_prompt(text), model=model, tokenizer=tokenizer)\n",
    "    #print(f\"Correct Loss: {correct_loss}\") ## Debugiing\n",
    "    \n",
    "    #print(get_incorrect_prompt(text)) ## Debugging\n",
    "    incorrect_loss = calc_loss(phrase=get_incorrect_prompt(text), model=model, tokenizer=tokenizer)\n",
    "    #print(f\"Incorrect Loss: {incorrect_loss}\") ## Debugging\n",
    "\n",
    "    pred_num = 1 if correct_loss < incorrect_loss else 0\n",
    "    \n",
    "    res[\"Correct_Loss\"] = correct_loss\n",
    "    res[\"Inorrect_Loss\"] = incorrect_loss\n",
    "    res[\"pred\"] = pred_num\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f675adea-f395-476c-9a2b-0c778a1f1675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение далее корректное? Солнце садилось за горизонт. Ответ: да.\n",
      "Предложение далее корректное? Не стоит сидеть сложить руки. Ответ: нет.\n",
      "Предложение далее корректное? Иван вчера не позвонил. Ответ: да.\n"
     ]
    }
   ],
   "source": [
    "correct_prompt = get_correct_prompt(text, few_shots)\n",
    "print(correct_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "77f1231a-2da2-4f45-84e5-27fda695f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение далее корректное? Солнце садилось за горизонт. Ответ: да.\n",
      "Предложение далее корректное? Не стоит сидеть сложить руки. Ответ: нет.\n",
      "Предложение далее корректное? Иван вчера не позвонил. Ответ: нет.\n"
     ]
    }
   ],
   "source": [
    "incorrect_prompt = get_incorrect_prompt(text, few_shots)\n",
    "print(incorrect_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a65cbe04-692c-458a-91b9-b1d6978fea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение далее корректное? Солнце садилось за горизонт. Ответ: да.\n",
      "Предложение далее корректное? Не стоит сидеть сложить руки. Ответ: нет.\n",
      "Предложение далее корректное? Иван вчера не позвонил. Ответ: да.\n",
      "Correct Loss: 2.8430206775665283\n",
      "Предложение далее корректное? Солнце садилось за горизонт. Ответ: да.\n",
      "Предложение далее корректное? Не стоит сидеть сложить руки. Ответ: нет.\n",
      "Предложение далее корректное? Иван вчера не позвонил. Ответ: нет.\n",
      "Incorrect Loss: 2.852612257003784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Correct_Loss': 2.8430206775665283,\n",
       " 'Inorrect_Loss': 2.852612257003784,\n",
       " 'pred': 1}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = get_few_shot_pred(text)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "00e78fd7-ea50-4145-835e-6feb21b1c0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "16eef412-78ad-4a45-839a-67e8102918f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef58b4ba67d64660b982587edd741781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fewshot_preds = []\n",
    "\n",
    "for text in tqdm(test_ds['text']):\n",
    "    out = get_few_shot_pred(text)\n",
    "    fewshot_preds.append(out['pred'])\n",
    "    #print(out,'\\n') ## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "06b47317-7809-44fd-9e72-23c730198d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fewshot_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "93d6a237-942a-4d0b-ae1a-1d15e73930ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.12      0.15       250\n",
      "           1       0.74      0.84      0.79       733\n",
      "\n",
      "    accuracy                           0.66       983\n",
      "   macro avg       0.47      0.48      0.47       983\n",
      "weighted avg       0.60      0.66      0.63       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_targets, fewshot_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e85d58c0-6b8e-41f2-b925-720218099e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.66\n",
      "Precision: 0.738\n",
      "   Recall: 0.844\n",
      " F1-score: 0.788\n",
      "      AUC: 0.482\n"
     ]
    }
   ],
   "source": [
    "results['Few-shots'] = quality(eval_targets, fewshot_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2d392ade-7468-4cd7-9b88-559513ebe86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-shot</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few-shots</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT        0.784      0.782   0.985     0.872  0.590\n",
       "Zero-shot     0.319      0.684   0.162     0.262  0.471\n",
       "Few-shots     0.660      0.738   0.844     0.788  0.482"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfd98e-f1de-47a0-9a75-5f33b8d20c43",
   "metadata": {},
   "source": [
    "C few-shots подходом результаты лучше, по сравнению с zero-shot, но файнтьюн Берта демонстрирует лучшие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c56b03-d0a0-4ea5-b8f5-e8724185a00f",
   "metadata": {},
   "source": [
    "## RuT5 finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6370e3-97c1-4124-84c7-aea4bec45e18",
   "metadata": {},
   "source": [
    "Обучите и протестируйте модель [RuT5](https://huggingface.co/ai-forever/ruT5-base) на данной задаче - пример finetun’а можете найти [здесь](https://github.com/RussianNLP/RuCoLA/blob/main/baselines/finetune_t5.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31c0a7-4665-4312-93a5-da62e3687bff",
   "metadata": {},
   "source": [
    "RuT5 finetuning\n",
    "```python\n",
    "python baselines/finetune_t5.py -m [MODEL_NAME]\n",
    "```\n",
    "Afterwards, you can get test set predictions in the format required by the leaderboard for all trained models. To do this, run \n",
    "```python\n",
    "python baselines/get_csv_predictions.py -m MODEL1 MODEL2 ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbb549-abca-4d5f-90dc-f983cceb2295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d21e929b-9bc7-4c9b-9095-9dbfbf78d6d3",
   "metadata": {},
   "source": [
    "## Итоговое сравнение полученных результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a401f0d-a501-4b32-84fb-816cc79f46b6",
   "metadata": {},
   "source": [
    "Отсортируем полученные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "05a12c79-146e-4a34-9f65-7da6410e744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ruBERT</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Few-shots</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-shot</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Precision  Recall  F1-score    AUC\n",
       "ruBERT        0.784      0.782   0.985     0.872  0.590\n",
       "Few-shots     0.660      0.738   0.844     0.788  0.482\n",
       "Zero-shot     0.319      0.684   0.162     0.262  0.471"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, index = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']).T.sort_values(by=['AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cb5de-ce58-4b2c-bcf4-105ed31a2edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
