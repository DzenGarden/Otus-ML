{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Создание тг-бота с LLM\n",
    "\n",
    "**Цель:**\n",
    "\n",
    "В данном домашнем задании вы создадите телеграм-ботов и интегрируете свои модели в телеграм-ботов.\n",
    "\n",
    "### Описание / Пошаговая инструкция выполнения домашнего задания:\n",
    "\n",
    "1. Возьмите ОДНУ из задач, с которой вы работали на курсе (например, задачу sentiment analysis или задачу из бенчмарка ruMTEB).\n",
    "\n",
    "2. Зафайнтьюньте модель с сайта Huggingface для выбранной задачи (например, энкодерную модель, такую как ruBERT, или энкодер-декодерную модель, такую как ruT5). В случае если вы берёте задачу для sentence-transformer и задачу из бенчмарка ruMTEB, необходимо написать pipeline применения модели для задачи и её решения, как в ДЗ про sentence-transformer.\n",
    "\n",
    "3. Создайте телеграм-бота, в котором будет поднята эта модель. Бот должен вначале писать вводное сообщение с описанием задачи, обрабатывать запрос пользователя и выводить ответ для заданного пользователем примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RP3Wwdg0Dwtl"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig  \n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import requests\n",
    "import telebot\n",
    "from telebot import types\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Выбор задачи и модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве набора данных я выбрал \"Yes/no Question Answering Dataset for the Russian\" бенчмарка [Russian SuperGLUE](https://russiansuperglue.com/tasks/). Набор данных содержит пары текстовых фрагментов, в частности, контекст и вопрос, а от модели ожидается ответ Да или Нет. Соответственно, решаем задачу бинарной классификации, а в качестве модели возьмем ruBert-base из репозитория ai-forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"ai-forever/ruBert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180,
     "referenced_widgets": [
      "6fcd13071b9a4df4bfa302ee706c5bcc",
      "c53ce2059c7244fba7897a3cb12fd3c3",
      "22e57396921f4cd0b296252fdfa3dbeb",
      "6179dcb02a934b7a94a09dd3f0d07671",
      "b7f8d976eba44b1dae2b71504f4299aa",
      "a822819b9a654e4cb63fa04c20176990",
      "629d7b0dba6d44afaa74ae35df10db60",
      "b26e87414c9c458cab4fb89c4b5659a9",
      "784bdf1b320e4d0ab6c9b1c5a9fee6a4",
      "04ec16f4e41f44cb9212a2ee4a865d8b",
      "eef55784ec134af0b4e11df1068dd9f1",
      "058643eac9db42e0b6d4f9cca49870f2",
      "3d9a341214554f3b90b74a4e08ec7468",
      "6bb96e15408e41c48092bef7068eb8e9",
      "8685f86414ab4df395d43e17b570dfaf",
      "d45da0d334c847a384e564368ce65016",
      "e51e7ed01ed544ac9af1e721889b2f88",
      "5d99602ff6264230b6b02c2f18ac68d9",
      "954eaace5b314bd0b2b420c749127023",
      "5da55e9178de48deae8b0245ba803f21",
      "29379500c6fa4157a8e6811298d7cae9",
      "66cdf91844e64327861eea258a3ffadc",
      "baa74b0836ea49cea73ba4e1325ff39d",
      "82ecb469ef6045eea6fa1f00fdaffce0"
     ]
    },
    "id": "MyuyrVa9D-Fc",
    "outputId": "b0bd7595-3656-47c0-a601-ee4f87c303af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='ai-forever/ruBert-base', vocab_size=120138, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_ckpt, do_lower_case=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c1c1503795ad4b1b9c9e8c11a41db978",
      "217c7757273e4762a0cb7e25aaad433b",
      "ae8af02b76bf4f7cbca0d0f45263088f",
      "afbfce35a1aa414689447dfc2c0e2f96",
      "9aed1a53164d4ab8a5852f369216d184",
      "ed3602e69d6041918ccd9af5056f973f",
      "237d756b48d54ffb94f3fa650f574210",
      "cdbe407f50694dae8d1205edd35ab8d2",
      "31b6fbb34af94cb4ad7b642d5a4f294a",
      "ebbe14a2fb4547908689a83e27604b32",
      "313295c7814a456bba9a3d95847d931d",
      "eba914fb8d4845b7943475f749b928c4",
      "d2b02d8428f9434aa26ce189e92f4717",
      "fe8db243b638460bb010064f876abbee",
      "57215d9b48594cb1a8de16b205d4d164",
      "63ad0a557f134b54995c8426b2d324d0"
     ]
    },
    "id": "-U0C4m4N0GrX",
    "outputId": "fa6836e1-7e20-4add-cd91-d7fc34ac1c10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, \n",
    "    num_labels = 2, \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KqrUdmFDEVfW"
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 2e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZQBiNIl1EVrH"
   },
   "outputs": [],
   "source": [
    "def load_data(tokenizer, questions, passages, max_length):\n",
    "    \"\"\"Encode the question/passage pairs into features than can be fed to the model.\"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for question, passage in zip(questions, passages):\n",
    "        encoded_data = tokenizer.encode_plus(question, passage, max_length=max_length, pad_to_max_length=True, truncation_strategy=\"longest_first\")\n",
    "        encoded_pair = encoded_data[\"input_ids\"]\n",
    "        attention_mask = encoded_data[\"attention_mask\"]\n",
    "\n",
    "        input_ids.append(encoded_pair)\n",
    "        attention_masks.append(attention_mask)\n",
    "    return np.array(input_ids), np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные для обучения и валидации из датасета [Russian SuperGLUE](https://russiansuperglue.com/tasks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Был ли джиган в black star?</td>\n",
       "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi конкурент apple?</td>\n",
       "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли автомат калашникова в вов?</td>\n",
       "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0      Вднх - это выставочный центр?   \n",
       "1      Вднх - это выставочный центр?   \n",
       "2        Был ли джиган в black star?   \n",
       "3            Xiaomi конкурент apple?   \n",
       "4  Был ли автомат калашникова в вов?   \n",
       "\n",
       "                                             passage  label  idx  \n",
       "0  «Вы́ставочный центр» — станция Московского мон...   True    0  \n",
       "1  Вы́ставка достиже́ний наро́дного хозя́йства  ,...   True    1  \n",
       "2  Вместе с этим треком они выступили на церемони...   True    2  \n",
       "3  Xiaomi — китайская компания, основанная в 2010...   True    3  \n",
       "4  Отметив некоторые недостатки и в целом удачную...  False    4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df = pd.read_json('./data/DaNetQA/train.jsonl', lines=True)\n",
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Есть ли вода на марсе?</td>\n",
       "      <td>Гидросфера Марса — это совокупность водных зап...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Состоит ли англия в евросоюзе?</td>\n",
       "      <td>В полночь с 31 января на 1 февраля 2020 года п...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Действительно ли в ссср не было адвокатов?</td>\n",
       "      <td>Семён Львович Ария  — советский и российский ю...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Была ли чума в оране?</td>\n",
       "      <td>Чума — это и абсурд, что осмысливается как фор...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли кетчуп в читосе?</td>\n",
       "      <td>Текущий каталог продукции размещен на сайте пр...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "0                      Есть ли вода на марсе?   \n",
       "1              Состоит ли англия в евросоюзе?   \n",
       "2  Действительно ли в ссср не было адвокатов?   \n",
       "3                       Была ли чума в оране?   \n",
       "4                     Был ли кетчуп в читосе?   \n",
       "\n",
       "                                             passage  label  idx  \n",
       "0  Гидросфера Марса — это совокупность водных зап...   True    0  \n",
       "1  В полночь с 31 января на 1 февраля 2020 года п...  False    1  \n",
       "2  Семён Львович Ария  — советский и российский ю...  False    2  \n",
       "3  Чума — это и абсурд, что осмысливается как фор...   True    3  \n",
       "4  Текущий каталог продукции размещен на сайте пр...   True    4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_df = pd.read_json('./data/DaNetQA/val.jsonl', lines=True)\n",
    "dev_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5KvnYIdFedx",
    "outputId": "6af2a79e-d156-4336-af10-f5dff2760c31",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "passages_train = train_data_df.passage.values\n",
    "questions_train = train_data_df.question.values\n",
    "answers_train = train_data_df.label.values.astype(int)\n",
    "print(answers_train)\n",
    "\n",
    "passages_dev = dev_data_df.passage.values\n",
    "questions_dev = dev_data_df.question.values\n",
    "answers_dev = dev_data_df.label.values.astype(int)\n",
    "\n",
    "# Encoding data\n",
    "max_seq_length = 256\n",
    "input_ids_train, attention_masks_train = load_data(tokenizer, questions_train, passages_train, max_seq_length)\n",
    "input_ids_dev, attention_masks_dev = load_data(tokenizer, questions_dev, passages_dev, max_seq_length)\n",
    "\n",
    "train_features = (input_ids_train, attention_masks_train, answers_train)\n",
    "dev_features = (input_ids_dev, attention_masks_dev, answers_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vCZQyqi0F9vz"
   },
   "outputs": [],
   "source": [
    "# Building Dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_features_tensors = [torch.tensor(feature, dtype=torch.long) for feature in train_features]\n",
    "dev_features_tensors = [torch.tensor(feature, dtype=torch.long) for feature in dev_features]\n",
    "\n",
    "train_dataset = TensorDataset(*train_features_tensors)\n",
    "dev_dataset = TensorDataset(*dev_features_tensors)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "dev_sampler = SequentialSampler(dev_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "dev_dataloader = DataLoader(dev_dataset, sampler=dev_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка данных завершена, переходим к обучению модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine tuning ruBert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iToAeF48X7MB"
   },
   "outputs": [],
   "source": [
    "# Number of EPOCHS\n",
    "EPOCHS = 10\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jDC4XrXWGF3K"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tbet3j4bCEZB",
    "outputId": "6b28431b-1840-4df1-c184-3c6e3462e8be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.6072 train_acc: 0.6792 | val_loss: 0.7577 val_acc: 0.5773\n",
      "00:00:09.76\n",
      "Epoch 2: train_loss: 0.4637 train_acc: 0.7994 | val_loss: 0.9792 val_acc: 0.5545\n",
      "00:00:09.68\n",
      "Epoch 3: train_loss: 0.3152 train_acc: 0.8744 | val_loss: 0.7323 val_acc: 0.6321\n",
      "00:00:09.63\n",
      "Epoch 4: train_loss: 0.1767 train_acc: 0.9361 | val_loss: 0.9673 val_acc: 0.6338\n",
      "00:00:09.65\n",
      "Epoch 5: train_loss: 0.0938 train_acc: 0.9736 | val_loss: 1.1653 val_acc: 0.6489\n",
      "00:00:09.67\n",
      "Epoch 6: train_loss: 0.0654 train_acc: 0.9784 | val_loss: 1.4057 val_acc: 0.6513\n",
      "00:00:09.66\n",
      "Epoch 7: train_loss: 0.0327 train_acc: 0.9892 | val_loss: 1.6646 val_acc: 0.6344\n",
      "00:00:09.68\n",
      "Epoch 8: train_loss: 0.0237 train_acc: 0.9923 | val_loss: 1.6828 val_acc: 0.6573\n",
      "00:00:09.67\n",
      "Epoch 9: train_loss: 0.0171 train_acc: 0.9949 | val_loss: 1.8685 val_acc: 0.6399\n",
      "00:00:09.63\n",
      "Epoch 10: train_loss: 0.0110 train_acc: 0.9966 | val_loss: 1.8901 val_acc: 0.6435\n",
      "00:00:09.65\n"
     ]
    }
   ],
   "source": [
    "# seting initial best loss to infinite\n",
    "best_eval_loss = float('inf')\n",
    "\n",
    "train_losses_history = []\n",
    "val_losses_history = []\n",
    "\n",
    "#for _ in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  # Training\n",
    "  model.train()\n",
    "\n",
    "  # Reset the total loss and accuracy for this epoch.\n",
    "  total_train_loss = 0\n",
    "  total_train_acc = 0\n",
    "  \n",
    "  # Measure how long the training epoch takes.\n",
    "  start = time.time()\n",
    "\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "      # Unpack this training batch from our dataloader.\n",
    "      input_ids = batch[0].to(device)\n",
    "      attention_masks = batch[1].to(device)\n",
    "      labels = batch[2].to(device)  \n",
    "\n",
    "      #clear any previously calculated gradients before performing a backward pass\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      #result = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels)\n",
    "      loss, prediction = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels).values()\n",
    "      #loss = result.loss\n",
    "      #logits = result.logits\n",
    "      acc = accuracy(prediction, labels)\n",
    "\n",
    "      # Accumulate the training loss and accuracy over all of the batches so that we can\n",
    "      # calculate the average loss at the end\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      # Perform a backward pass to calculate the gradients.\n",
    "      loss.backward()\n",
    "\n",
    "      # Clip the norm of the gradients to 1.0.\n",
    "      # This is to help prevent the \"exploding gradients\" problem.\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "      # Update parameters and take a step using the computed gradient.\n",
    "      optimizer.step()\n",
    "\n",
    "      # Update the learning rate.\n",
    "      scheduler.step()\n",
    "\n",
    "  # Calculate the average accuracy and loss over all of the batches.\n",
    "  train_acc  = total_train_acc/len(train_dataloader)\n",
    "  train_loss = total_train_loss/len(train_dataloader)\n",
    "  train_losses_history.append(train_loss)\n",
    "\n",
    "  # Put the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in dev_dataloader:\n",
    "\n",
    "      #clear any previously calculated gradients before performing a backward pass\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Unpack this validation batch from our dataloader.\n",
    "      input_ids = batch[0].to(device)\n",
    "      attention_masks = batch[1].to(device)\n",
    "      labels = batch[2].to(device) \n",
    "\n",
    "      #Get the loss and prediction\n",
    "      loss, prediction = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels).values()\n",
    "\n",
    "      # Calculate the accuracy for this batch\n",
    "      acc = accuracy(prediction, labels)\n",
    "\n",
    "      # Accumulate the validation loss and Accuracy\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "  # Calculate the average accuracy and loss over all of the batches.\n",
    "  val_acc  = total_val_acc/len(dev_dataloader)\n",
    "  val_loss = total_val_loss/len(dev_dataloader)\n",
    "  val_losses_history.append(val_loss)\n",
    "\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "  #save the best model\n",
    "  if val_loss < best_eval_loss:\n",
    "      best_eval_loss = val_loss\n",
    "      torch.save(model.state_dict(), 'ruBert_saved_weights.pt')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss over Epochs')\n",
    "plt.plot(np.arange(1,EPOCHS+1), train_losses_history, label='Train Loss')\n",
    "plt.plot(np.arange(1,EPOCHS+1), val_losses_history, label='Validation Loss')\n",
    "plt.xticks(np.arange(1,EPOCHS+1))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the best saved model\n",
    "path = 'ruBert_saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим на тестовых данных, что предсказывает модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6ahfHpJugsEV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Полезна ли ртуть с градусника?</td>\n",
       "      <td>Отравления ртутью  — расстройства здоровья, св...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Являются ли сапрофаги хищниками?</td>\n",
       "      <td>Фауна лесных почв — совокупность видов животны...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Водятся ли в индии крокодилы?</td>\n",
       "      <td>Болотный крокодил, или магер  — пресмыкающееся...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Есть ли в батате крахмал?</td>\n",
       "      <td>Клубневидно вздутые корни  весят до 15 кг, сод...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли человек в железной маске?</td>\n",
       "      <td>Остров Сент-Маргерит  — крупнейший из Лерински...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           question  \\\n",
       "0    Полезна ли ртуть с градусника?   \n",
       "1  Являются ли сапрофаги хищниками?   \n",
       "2     Водятся ли в индии крокодилы?   \n",
       "3         Есть ли в батате крахмал?   \n",
       "4  Был ли человек в железной маске?   \n",
       "\n",
       "                                             passage  idx  \n",
       "0  Отравления ртутью  — расстройства здоровья, св...    0  \n",
       "1  Фауна лесных почв — совокупность видов животны...    1  \n",
       "2  Болотный крокодил, или магер  — пресмыкающееся...    2  \n",
       "3  Клубневидно вздутые корни  весят до 15 кг, сод...    3  \n",
       "4  Остров Сент-Маргерит  — крупнейший из Лерински...    4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test data\n",
    "test_data_df = pd.read_json('./data/DaNetQA/test.jsonl', lines=True)\n",
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "k9l-1W37tvDV"
   },
   "outputs": [],
   "source": [
    "passage_list = test_data_df['passage'].to_list()\n",
    "question_list = test_data_df['question'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "A-8K7nG6VQT0"
   },
   "outputs": [],
   "source": [
    "# Predict the answer\n",
    "def predict(question, passage):\n",
    "  sequence = tokenizer.encode_plus(question, passage, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "  logits = model(sequence)[0]\n",
    "  probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
    "  proba_yes = round(probabilities[1], 3)\n",
    "  proba_no = round(probabilities[0], 3)\n",
    "  print(f\"Question: {question}, True: {proba_yes}, False: {proba_no}\")\n",
    "  return f\"True: {proba_yes}, False: {proba_no}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1I-bxn0GVSjz",
    "outputId": "8d334f25-f54c-423f-efc7-3ae8ca49376a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Существует ли в российской федерации своя платежная система?, True: 0.22, False: 0.78\n",
      "Question: Вредно ли пить витамин д?, True: 0.526, False: 0.474\n",
      "Question: Были ли ассасины выдумкой?, True: 0.766, False: 0.234\n",
      "Question: Входит ли в понятие информационной безопасности организация противоправного изменения информации?, True: 0.487, False: 0.513\n",
      "Question: Правда ли были динозавры?, True: 0.915, False: 0.085\n",
      "Question: Входит ли швейцария в нато?, True: 0.028, False: 0.972\n",
      "Question: Правда ли что зарплата не входит в себестоимость?, True: 0.642, False: 0.358\n",
      "Question: Разрешено ли в америке двойное гражданство?, True: 0.439, False: 0.561\n",
      "Question: Состоит ли грузия в нато?, True: 0.119, False: 0.881\n",
      "Question: Все ли брахманы запрещают есть рыбу?, True: 0.257, False: 0.743\n"
     ]
    }
   ],
   "source": [
    "sample_ids = random.sample(range(1, len(question_list)), 10)\n",
    "\n",
    "#for i in range(1,11):\n",
    "for i in sample_ids:\n",
    "    question = question_list[i]\n",
    "    passage = passage_list[i]\n",
    "    predict(question,passage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Telegram Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2token = './OracleBiBot_token.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path2token) as f:\n",
    "    TOKEN = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bot_url(path):\n",
    "    with open(path) as f:\n",
    "        TOKEN = f.read().strip()\n",
    "    bot_url = f'https://api.telegram.org/bot{TOKEN}'\n",
    "    return bot_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(text: str, channel_id: int, reply_to: int=None, reply_markup: dict=None):\n",
    "    \"\"\"text: string of any length\n",
    "       channel_id: int - chat id\n",
    "       reply_to: int message to reply id\n",
    "       reply_markup: dict {inline_keyboard: [[{ text: 'Stop', callback_data: \"string\" }]],}\n",
    "       return: list of response objects. res[0].status_code, res[0].json()\n",
    "    \"\"\"\n",
    "    \n",
    "    method = make_bot_url(path2token) + \"/sendMessage\"\n",
    "\n",
    "    res = []\n",
    "    if len(text) > 4096:\n",
    "        for x in range(0, len(text), 4096):\n",
    "            text_ = text[x:x + 4096]\n",
    "            data = {\n",
    "                \"chat_id\": channel_id,\n",
    "                \"text\": text_\n",
    "            }\n",
    "            \n",
    "            if reply_to:\n",
    "                data['reply_to_message_id'] = reply_to\n",
    "\n",
    "            r = requests.post(method, data=data)\n",
    "            res.append(r)\n",
    "    else:\n",
    "        data = {\n",
    "            \"chat_id\": channel_id,\n",
    "            \"text\": text\n",
    "        }\n",
    "        \n",
    "        if reply_markup:\n",
    "            assert type(reply_markup) == dict\n",
    "            data['reply_markup'] = json.dumps(reply_markup)\n",
    "        \n",
    "        if reply_to:\n",
    "            data['reply_to_message_id'] = reply_to\n",
    "\n",
    "        r = requests.post(method, data=data)\n",
    "        res.append(r)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am binary oracle bot'\n",
    "my_chat_id = 406137873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Response [200]>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = send_message(text=text, channel_id=my_chat_id)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://api.telegram.org/bot{TOKEN}' + \"/getMe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'result': {'id': 7662060530,\n",
       "  'is_bot': True,\n",
       "  'first_name': 'OracleBI',\n",
       "  'username': 'OracleBiBot',\n",
       "  'can_join_groups': True,\n",
       "  'can_read_all_group_messages': False,\n",
       "  'supports_inline_queries': False,\n",
       "  'can_connect_to_business': False,\n",
       "  'has_main_web_app': False}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "welcome_message = 'Вас приветствует бот, обученный давать бинарные ответы\\nОпишите контекст, задайте вопрос с новой строки - и вы получите ответ:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = telebot.TeleBot(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 16:26:04,426 (__init__.py:1121 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
      "2025-09-27 16:26:04,426 (__init__.py:1123 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n"
     ]
    }
   ],
   "source": [
    "@bot.message_handler(commands=['start'])\n",
    "def start_message(message):\n",
    "    bot.send_message(message.chat.id, welcome_message)\n",
    "\n",
    "@bot.message_handler(func=lambda x: True, chat_types=[\"private\"])\n",
    "def start_message(message):\n",
    "    print(message.text)\n",
    "    #bot.send_message(message.chat.id, \"<b>Any other</b> <i>handler</i>\", parse_mode=\"HTML\")\n",
    "    splits = message.text.split(sep=\"\\n\", maxsplit=1)\n",
    "    print(f\"C: {splits[0].strip()}\")\n",
    "    print(f\"Q: {splits[1].strip()}\")\n",
    "    answer = predict(splits[1].strip(), splits[0].strip())\n",
    "    print(answer)\n",
    "    bot.send_message(message.chat.id, f\"<b>Ответ на вопрос: {splits[1].strip()}</b>\\n<i>{answer}</i>\", parse_mode=\"HTML\")\n",
    "\n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot Screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/screenshot-disel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/screenshot-nato.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNNINKCkVgPQ+gdr6KHVjZw",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "PA4_boolq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04ec16f4e41f44cb9212a2ee4a865d8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "058643eac9db42e0b6d4f9cca49870f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d45da0d334c847a384e564368ce65016",
      "placeholder": "​",
      "style": "IPY_MODEL_8685f86414ab4df395d43e17b570dfaf",
      "value": " 28.0/28.0 [00:02&lt;00:00, 11.7B/s]"
     }
    },
    "217c7757273e4762a0cb7e25aaad433b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22e57396921f4cd0b296252fdfa3dbeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a822819b9a654e4cb63fa04c20176990",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7f8d976eba44b1dae2b71504f4299aa",
      "value": 231508
     }
    },
    "237d756b48d54ffb94f3fa650f574210": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29379500c6fa4157a8e6811298d7cae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "313295c7814a456bba9a3d95847d931d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe8db243b638460bb010064f876abbee",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2b02d8428f9434aa26ce189e92f4717",
      "value": 440473133
     }
    },
    "31b6fbb34af94cb4ad7b642d5a4f294a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_313295c7814a456bba9a3d95847d931d",
       "IPY_MODEL_eba914fb8d4845b7943475f749b928c4"
      ],
      "layout": "IPY_MODEL_ebbe14a2fb4547908689a83e27604b32"
     }
    },
    "3d9a341214554f3b90b74a4e08ec7468": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "57215d9b48594cb1a8de16b205d4d164": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d99602ff6264230b6b02c2f18ac68d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5da55e9178de48deae8b0245ba803f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ecb469ef6045eea6fa1f00fdaffce0",
      "placeholder": "​",
      "style": "IPY_MODEL_baa74b0836ea49cea73ba4e1325ff39d",
      "value": " 466k/466k [00:00&lt;00:00, 488kB/s]"
     }
    },
    "6179dcb02a934b7a94a09dd3f0d07671": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b26e87414c9c458cab4fb89c4b5659a9",
      "placeholder": "​",
      "style": "IPY_MODEL_629d7b0dba6d44afaa74ae35df10db60",
      "value": " 232k/232k [00:05&lt;00:00, 43.1kB/s]"
     }
    },
    "629d7b0dba6d44afaa74ae35df10db60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63ad0a557f134b54995c8426b2d324d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66cdf91844e64327861eea258a3ffadc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bb96e15408e41c48092bef7068eb8e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fcd13071b9a4df4bfa302ee706c5bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22e57396921f4cd0b296252fdfa3dbeb",
       "IPY_MODEL_6179dcb02a934b7a94a09dd3f0d07671"
      ],
      "layout": "IPY_MODEL_c53ce2059c7244fba7897a3cb12fd3c3"
     }
    },
    "784bdf1b320e4d0ab6c9b1c5a9fee6a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eef55784ec134af0b4e11df1068dd9f1",
       "IPY_MODEL_058643eac9db42e0b6d4f9cca49870f2"
      ],
      "layout": "IPY_MODEL_04ec16f4e41f44cb9212a2ee4a865d8b"
     }
    },
    "82ecb469ef6045eea6fa1f00fdaffce0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8685f86414ab4df395d43e17b570dfaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "954eaace5b314bd0b2b420c749127023": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66cdf91844e64327861eea258a3ffadc",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29379500c6fa4157a8e6811298d7cae9",
      "value": 466062
     }
    },
    "9aed1a53164d4ab8a5852f369216d184": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a822819b9a654e4cb63fa04c20176990": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae8af02b76bf4f7cbca0d0f45263088f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed3602e69d6041918ccd9af5056f973f",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9aed1a53164d4ab8a5852f369216d184",
      "value": 570
     }
    },
    "afbfce35a1aa414689447dfc2c0e2f96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdbe407f50694dae8d1205edd35ab8d2",
      "placeholder": "​",
      "style": "IPY_MODEL_237d756b48d54ffb94f3fa650f574210",
      "value": " 570/570 [00:34&lt;00:00, 16.6B/s]"
     }
    },
    "b26e87414c9c458cab4fb89c4b5659a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7f8d976eba44b1dae2b71504f4299aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "baa74b0836ea49cea73ba4e1325ff39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1c1503795ad4b1b9c9e8c11a41db978": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae8af02b76bf4f7cbca0d0f45263088f",
       "IPY_MODEL_afbfce35a1aa414689447dfc2c0e2f96"
      ],
      "layout": "IPY_MODEL_217c7757273e4762a0cb7e25aaad433b"
     }
    },
    "c53ce2059c7244fba7897a3cb12fd3c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdbe407f50694dae8d1205edd35ab8d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b02d8428f9434aa26ce189e92f4717": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d45da0d334c847a384e564368ce65016": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e51e7ed01ed544ac9af1e721889b2f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_954eaace5b314bd0b2b420c749127023",
       "IPY_MODEL_5da55e9178de48deae8b0245ba803f21"
      ],
      "layout": "IPY_MODEL_5d99602ff6264230b6b02c2f18ac68d9"
     }
    },
    "eba914fb8d4845b7943475f749b928c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63ad0a557f134b54995c8426b2d324d0",
      "placeholder": "​",
      "style": "IPY_MODEL_57215d9b48594cb1a8de16b205d4d164",
      "value": " 440M/440M [00:08&lt;00:00, 51.3MB/s]"
     }
    },
    "ebbe14a2fb4547908689a83e27604b32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed3602e69d6041918ccd9af5056f973f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eef55784ec134af0b4e11df1068dd9f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bb96e15408e41c48092bef7068eb8e9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d9a341214554f3b90b74a4e08ec7468",
      "value": 28
     }
    },
    "fe8db243b638460bb010064f876abbee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
